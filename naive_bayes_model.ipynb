{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o Modelo (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from unidecode import unidecode\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv('./data/imdb-reviews-pt-br.csv')\n",
    "df_imdb = df_imdb[['text_pt', 'sentiment']]\n",
    "df_imdb.columns = ['text', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.read_csv('./data/negativo.csv', header=None)\n",
    "df_pos = pd.read_csv('./data/positivo.csv', header=None)\n",
    "\n",
    "df_pos['sentiment'] = 'pos'\n",
    "df_neg['sentiment'] = 'neg'\n",
    "df_neg.columns = ['text', 'sentiment']\n",
    "df_pos.columns = ['text', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_imdb, df_pos, df_neg]\n",
    "dfTreino = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeamento = {'pos': 'Positivo', 'neg': 'Negativo'}\n",
    "\n",
    "# Aplica o mapeamento à coluna\n",
    "dfTreino['sentiment'] = dfTreino['sentiment'].map(mapeamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo hashtags e menções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpando_chars(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # Removendo menções\n",
    "    text = re.sub(r'#\\w+', '', text) # Removendo #hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'_', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pre-processed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>mais uma vez, o sr. costner arrumou um filme p...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>nem mesmo os beatles puderam escrever músicas ...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...   \n",
       "\n",
       "                                       pre-processed sentiment  \n",
       "0  mais uma vez, o sr. costner arrumou um filme p...  Negativo  \n",
       "1  este é um exemplo do motivo pelo qual a maiori...  Negativo  \n",
       "2  primeiro de tudo eu odeio esses raps imbecis, ...  Negativo  \n",
       "3  nem mesmo os beatles puderam escrever músicas ...  Negativo  \n",
       "4  filmes de fotos de latão não é uma palavra apr...  Negativo  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTreino['pre-processed'] = dfTreino['text'].apply(limpando_chars)\n",
    "dfTreino = dfTreino[['text', 'pre-processed', 'sentiment']]\n",
    "dfTreino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "pontuacao = []\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)\n",
    "\n",
    "stopwords = pontuacao = stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização e Stemmização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_space = tokenize.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função processar_texto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_texto(texto):\n",
    "    stemmer = nltk.RSLPStemmer()\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    texto = re.sub(r'@[A-Za-z0-9]+', '', texto) # Removendo menções\n",
    "    texto = re.sub(r'#\\w+', '', texto) # Removendo #hashtags\n",
    "    texto = re.sub(r'#', '', texto)\n",
    "    texto = re.sub(r'_', '', texto)\n",
    "    texto = re.sub(r'RT[\\s]+', '', texto)\n",
    "    texto = re.sub(r'https?:\\/\\/\\S+', '', texto)\n",
    "    texto = re.sub(r'\\n', '', texto)\n",
    "    pontuacao = []\n",
    "    for ponto in punctuation:\n",
    "        pontuacao.append(ponto)\n",
    "    # Remove caracteres especiais\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    # Converte para minúsculas\n",
    "    texto = texto.lower()\n",
    "    texto = [stemmer.stem(palavra) for palavra in texto.split() if palavra not in stopwords]\n",
    "    # Une acentos\n",
    "    texto = [unidecode.unidecode(palavra) for palavra in texto]\n",
    "    return ' '.join(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o necessário. Além das terríveis seqüências de resgate no mar, das quais há muito poucas, eu simplesmente não me importei com nenhum dos personagens. A maioria de nós tem fantasmas no armário, e o personagem Costers é realizado logo no início, e depois esquecido até muito mais tarde, quando eu não me importava. O personagem com o qual deveríamos nos importar é muito arrogante e superconfiante, Ashton Kutcher. O problema é que ele sai como um garoto que pensa que é melhor do que qualquer outra pessoa ao seu redor e não mostra sinais de um armário desordenado. Seu único obstáculo parece estar vencendo Costner. Finalmente, quando estamos bem além do meio do caminho, Costner nos conta sobre os fantasmas dos Kutchers. Somos informados de por que Kutcher é levado a ser o melhor sem pressentimentos ou presságios anteriores. Nenhuma mágica aqui, era tudo que eu podia fazer para não desligar uma hora.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTreino['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vez sr costn arrum film temp necess alem terr sequ resgat mar qual pouc simples import nenhum person maior fantasm armari person cost realiz log inici esquec tard import person dev import arrog superconfi ashton kutch problem sai garot pens melhor qualqu outr pesso redor mostr sinal armari desorden unic obstacul parec venc costn final bem alem mei caminh costn cont sobr fantasm kutch inform kutch lev melhor pressent pressagi anteri nenhum magic aqu tud pod faz deslig hor\n"
     ]
    }
   ],
   "source": [
    "print(processar_texto(dfTreino['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreino['pre-processed'] = dfTreino['text'].apply(processar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pre-processed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>vez sr costn arrum film temp necess alem terr ...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>exempl motiv maior film aca mesm gener chat na...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>prim tud odei rap imbecil pod agir arm pressio...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>beatl pud escrev music tod gost emb walt hill ...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>film fot lat palavr apropri verdad tant ous qu...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...   \n",
       "\n",
       "                                       pre-processed sentiment  \n",
       "0  vez sr costn arrum film temp necess alem terr ...  Negativo  \n",
       "1  exempl motiv maior film aca mesm gener chat na...  Negativo  \n",
       "2  prim tud odei rap imbecil pod agir arm pressio...  Negativo  \n",
       "3  beatl pud escrev music tod gost emb walt hill ...  Negativo  \n",
       "4  film fot lat palavr apropri verdad tant ous qu...  Negativo  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTreino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Primeiro de tudo eu odeio esses raps imbecis, que não poderiam agir se tivessem uma arma pressionada contra suas testas. Tudo o que eles fazem é amaldiçoar e atirar um no outro e agir como uma versão clichê de gangsters. O filme não leva mais de cinco minutos para explicar o que está acontecendo antes que já estivessem no armazém. Não há um único personagem simpático nesse filme, com exceção do sem-teto, que também é o único com metade do cérebro. William Paxton e William Sadler são ambos \"hill billies\" e Sadler é tão vilão quanto os gângsteres. Eu não gostava dele desde o começo. O filme está cheio de violência sem sentido e especialidade de Walter Hills: pessoas caindo de janelas com vidros voando por toda parte. Não há praticamente nenhum enredo e é um grande problema quando você torce por ninguém. Todo mundo morre, exceto Paxton e o sem-teto e todos recebem o que merecem. Os dois únicos negros que podem atuar são o sem-teto e o viciado, mas são atores de profissão, não irritantes rappers feios. Fique longe dessa porcaria. e observe 48 horas 1 e 2 em vez disso. No mínimo, eles têm personagens de que você gosta, senso de humor e nada além de atores reais no elenco.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTreino.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prim tud odei rap imbecil pod agir arm pression contr test tud faz amaldico atir outr agir vers clich gangst film lev cinc minut explic acontec ant armazem unic person simpa ness film excec semtet unic metad cerebr will paxton will sadl ambos hill billi sadl tao vil quant gangst gost desd comec film chei viol sent especial walt hill pesso caind janel vidr vo tod part pratic nenhum enred grand problem torc ninguem tod mund morr excet paxton semtet tod receb merec doi unic negr pod atu semtet vici at profiss irrit rapp fei fiqu long dess porc observ 48 hor 1 2 vez diss min tem person gost sens hum nad alem at real elenc'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTreino['pre-processed'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8506234015345269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cria um vetorizador\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Transforma os textos em um vetor TF-IDF\n",
    "vetor_tfidf = tfidf.fit_transform(dfTreino['pre-processed'])\n",
    "\n",
    "# Divida os dados em um conjunto de treinamento e um conjunto de teste\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(vetor_tfidf, dfTreino['sentiment'], random_state=42)\n",
    "\n",
    "# Cria um modelo de Naive Bayes\n",
    "modelo = MultinomialNB(alpha=1.0)\n",
    "\n",
    "# Treina o modelo\n",
    "modelo.fit(treino, classe_treino)\n",
    "\n",
    "# Teste o modelo\n",
    "previsoes = modelo.predict(teste)\n",
    "\n",
    "# Calcula a acurácia do modelo\n",
    "acuracia = modelo.score(teste, classe_teste)\n",
    "\n",
    "print(acuracia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Acurácia  F1-score  Precisão    Recall\n",
      "  0.850623  0.847987  0.856697  0.839452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Calcula as métricas\n",
    "acuracia = accuracy_score(classe_teste, previsoes)\n",
    "f1_score = f1_score(classe_teste, previsoes, pos_label='Positivo')\n",
    "precision_score = precision_score(classe_teste, previsoes, pos_label='Positivo')\n",
    "recall_score = recall_score(classe_teste, previsoes, pos_label='Positivo')\n",
    "\n",
    "# Cria um DataFrame com as métricas\n",
    "metricas = pd.DataFrame({\n",
    "    'Acurácia': acuracia,\n",
    "    'F1-score': f1_score,\n",
    "    'Precisão': precision_score,\n",
    "    'Recall': recall_score\n",
    "}, index=[''])\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.84      0.86      0.85      6302\n",
      "    Positivo       0.86      0.84      0.85      6210\n",
      "\n",
      "    accuracy                           0.85     12512\n",
      "   macro avg       0.85      0.85      0.85     12512\n",
      "weighted avg       0.85      0.85      0.85     12512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "report = classification_report(classe_teste, previsoes)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'alpha': 1.0}\n",
      "Acurácia do modelo otimizado: 0.8506234015345269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=MultinomialNB(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(treino, classe_treino)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(teste)\n",
    "accuracy = accuracy_score(classe_teste, y_pred)\n",
    "print(\"Acurácia do modelo otimizado:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 0.85\n",
      "Desvio padrão da acurácia: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Defina o número de folds (k)\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "\n",
    "# Crie um objeto KFold para controlar a divisão dos dados\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Realize a validação cruzada\n",
    "scores = cross_val_score(modelo, vetor_tfidf , dfTreino['sentiment'], cv=kf, scoring='accuracy')\n",
    "mean_accuracy = scores.mean()\n",
    "std_accuracy = scores.std()\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função predict_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_it(frase):\n",
    "    # Aplica a função de pré-processamento\n",
    "    texto_processado = processar_texto(frase)\n",
    "    # Transforma o texto em um vetor TF-IDF\n",
    "    vetor_tfidf = tfidf.transform([texto_processado])\n",
    "    # Prevê a classificação da frase\n",
    "    previsao = modelo.predict(vetor_tfidf)\n",
    "    probabilidades = modelo.predict_proba(vetor_tfidf).astype('float')[0]\n",
    "    pos = probabilidades[1]\n",
    "    neg = probabilidades[0]\n",
    "    if pos < 0.51 and neg < 0.51:\n",
    "        return 'Neutro'\n",
    "    else:\n",
    "        return previsao.astype('str')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo\n"
     ]
    }
   ],
   "source": [
    "frase = 'ele foi muito bem'\n",
    "print(predict_it(frase))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/nb_predictor.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(modelo, './model/nb_predictor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf.vocabulary_,open(\"./model/tfidf.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
